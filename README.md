# Generating Animals using a Diffusion Model based on UNET

---- 
- **Chosen Paper:** [Diffusion Models Beat GANs on Image Synthesis [Dhariwal, Nichol, 2021]](https://openreview.net/pdf?id=AAWuCvzaVt)
- **Published at:** NeurIPS21
- **Reason for selection:** The reason for choosing this paper is because it had a big impact on how images are generated. The study showed that a diffusion model can produce better results than Generative Adversarial Networks (GANs). This discovery led to a significant change in how researchers approach image generation. By demonstrating better performance in creating images, the paper questioned the dominance of GANs, which have been the main method for making realistic images. This change not only drew a lot of interest from academics but also encouraged more study into diffusion models and how they could be used in different areas besides image generation. Overall, the paper provides important insights and has sparked new ideas for research in visual media and artificial intelligence.


----------
**Other Sources**
- Used Dataset ([Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/))
- Used Tutorials ([Diffusion Models - Live Coding Tutorial
](https://youtu.be/S_il77Ttrmg), )
- Used Repositories ([Denoising Diffusion Pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch), [The Annotated Diffusion Model](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/annotated_diffusion.ipynb#scrollTo=3a159023))

-------
**Modification Overview:**
- Dataset change to Dogs and Cats
- Changed order and structure of code blocks
- Code adjustments and comments
- Tested different hyper parameters such as batch sizes, epochs, etc.
- Added weight saving and resuming mechanism
--------
